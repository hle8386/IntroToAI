{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your ZIP file\n",
    "zip_path = r\"C:\\Users\\hoang le\\Downloads\\archive.zip\"\n",
    "extract_dir = r\"C:\\Users\\hoang le\\Downloads\\extracted\"\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'benign': 0, 'malignant': 1, 'normal': 2}\n"
     ]
    }
   ],
   "source": [
    "categories = [\"benign\", \"malignant\", \"normal\"]  # Label names\n",
    "label_mapping = {category: idx for idx, category in enumerate(categories)}\n",
    "\n",
    "print(f\"Label mapping: {label_mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (1578, 500, 500)\n",
      "Labels shape: (1578,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Initialize storage for images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Process each category\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(extract_dir, category)\n",
    "    label = label_mapping[category]  # Get the label for this category\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(('.png', '.jpg', '.jpeg', '.bmp')):  # Supported image formats\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            try:\n",
    "                # Open, convert to grayscale, and resize image\n",
    "                img = Image.open(file_path).convert('L').resize((500, 500))\n",
    "                images.append(np.array(img))  # Convert image to numpy array\n",
    "                labels.append(label)          # Store the label\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Display shapes\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X_train shape: (468, 500, 500), y_train shape: (468, 500, 500)\n",
      "Validation set: X_val shape: (156, 500, 500), y_val shape: (156, 500, 500)\n",
      "Test set: X_test shape: (156, 500, 500), y_test shape: (156, 500, 500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize lists to hold images (original and masks)\n",
    "original_images = []\n",
    "mask_images = []\n",
    "\n",
    "# Folder paths for each category\n",
    "categories = ['benign', 'normal', 'malignant']\n",
    "\n",
    "# Iterate over each category and load original and mask images\n",
    "for category in categories:\n",
    "    category_folder = os.path.join(extract_dir, category)  # Path to category folder\n",
    "    original_images_folder = os.path.join(category_folder)  # Path to original images\n",
    "    mask_images_folder = os.path.join(category_folder)  # Path to mask images\n",
    "    \n",
    "    # Iterate over the files in the original folder\n",
    "    for file in os.listdir(original_images_folder):\n",
    "        if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            # Extract the base name (without extension or \"_mask\")\n",
    "            base_name = os.path.splitext(file)[0]  # Remove file extension\n",
    "            \n",
    "            # Construct the path for the original image and corresponding mask image\n",
    "            original_image_path = os.path.join(original_images_folder, file)\n",
    "            mask_image_path = os.path.join(mask_images_folder, f\"{base_name}_mask{os.path.splitext(file)[1]}\")  # Add _mask to the base name\n",
    "            \n",
    "            if os.path.exists(mask_image_path):  # Ensure that mask image exists\n",
    "                # Open and convert to grayscale (if needed) and resize\n",
    "                original_image = Image.open(original_image_path).convert('L').resize((500, 500))\n",
    "                mask_image = Image.open(mask_image_path).convert('L').resize((500, 500))\n",
    "                \n",
    "                # Append to the lists\n",
    "                original_images.append(np.array(original_image))\n",
    "                mask_images.append(np.array(mask_image))\n",
    "\n",
    "# Convert lists to numpy arrays for easier manipulation\n",
    "original_images = np.array(original_images)\n",
    "mask_images = np.array(mask_images)\n",
    "\n",
    "# Split the dataset into X (original images) and Y (mask images)\n",
    "X = original_images\n",
    "y = mask_images\n",
    "\n",
    "# Now split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display dataset shapes\n",
    "print(f\"Training set: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"Validation set: X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"Test set: X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the original images (X) by scaling pixel values to [0, 1]\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
